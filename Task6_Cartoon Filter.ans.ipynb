{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT: Cartoon Face Mask\n",
    "## This assignment tests your ability to apply face recognition, image masks, image thresholding, video capturing and saving video feed into a video file concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK: Cartoonify faces in video feed from live webcam\n",
    "\n",
    "### Steps\n",
    "- 1. **Capture video** feed from webcam\n",
    "- 2. **Recognize faces** in the video\n",
    "- 3. **Replace/Mask the face** region with your favorite cartoon character\n",
    "- 4. **Save the video** feed into a video file\n",
    "- 5. Submit the following files\n",
    "    - Notebook (.ipynb)\n",
    "    - Video (.avi/.mp4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries and Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Set up paths for Haar Cascade XML files\n",
    "cascPathface = \"/Users/bishakha/Downloads/haarcascade_frontalface_alt2.xml\"\n",
    "cascPatheyes = \"/Users/bishakha/Downloads/haarcascade_eye_tree_eyeglasses.xml\"\n",
    "\n",
    "# Load Haar Cascade classifiers\n",
    "faceCascade = cv2.CascadeClassifier(cascPathface)\n",
    "eyeCascade = cv2.CascadeClassifier(cascPatheyes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Cartoon Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cartoon mask (ensure it's a PNG with transparency)\n",
    "mask = cv2.imread('cute.png', cv2.IMREAD_UNCHANGED)  # Load with alpha channel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Webcam Video Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize webcam video capture\n",
    "video_capture = cv2.VideoCapture(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Video Writer to Save Processed Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up video writer to save the processed video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  \n",
    "out = cv2.VideoWriter('masked_video.mp4v', fourcc, 20.0, (640, 480))  # Output video file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Video Frames and Detect Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 03:08:42.717 python[31406:2631312] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-03-27 03:08:42.717 python[31406:2631312] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    }
   ],
   "source": [
    "# Process video frames and detect faces\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces in the grayscale frame\n",
    "    faces = faceCascade.detectMultiScale(gray,\n",
    "                                         scaleFactor=1.1,\n",
    "                                         minNeighbors=5,\n",
    "                                         minSize=(60, 60),\n",
    "                                         flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    \n",
    "    # Loop over detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw rectangle around face\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Resize the cartoon mask to match the face's width and height\n",
    "        resized_mask = cv2.resize(mask, (w, h))\n",
    "\n",
    "        # Check if the mask has an alpha channel (transparency)\n",
    "        if resized_mask.shape[2] == 4:  # Has an alpha channel (PNG format)\n",
    "            alpha_mask = resized_mask[:, :, 3] / 255.0  # Normalize alpha values (0 to 1)\n",
    "            mask_rgb = resized_mask[:, :, :3]  # Extract the RGB part of the mask (without alpha)\n",
    "        else:\n",
    "            alpha_mask = np.ones((h, w))  # No transparency, so full opacity\n",
    "            mask_rgb = resized_mask  # Use the entire mask without alpha blending\n",
    "        \n",
    "        # Extract the face region of interest (ROI) from the frame\n",
    "        faceROI = frame[y:y+h, x:x+w]\n",
    "\n",
    "        # Apply the mask using alpha blending\n",
    "        for c in range(3):  # For R, G, B channels\n",
    "            faceROI[:, :, c] = (1 - alpha_mask) * faceROI[:, :, c] + alpha_mask * mask_rgb[:, :, c]\n",
    "\n",
    "        # Put the blended face region back into the frame\n",
    "        frame[y:y+h, x:x+w] = faceROI\n",
    "\n",
    "        # Detect eyes and draw circles around them (as per original code)\n",
    "        eyes = eyeCascade.detectMultiScale(faceROI)\n",
    "        for (x2, y2, w2, h2) in eyes:\n",
    "            eye_center = (x + x2 + w2 // 2, y + y2 + h2 // 2)\n",
    "            radius = int(round((w2 + h2) * 0.25))\n",
    "            frame = cv2.circle(frame, eye_center, radius, (255, 0, 0), 4)\n",
    "\n",
    "    # Display the resulting frame with cartoon mask overlay\n",
    "    cv2.imshow('Face Video with Mask', frame)\n",
    "    \n",
    "    # Exit the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Release Resources and Close Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release the video capture and writer objects\n",
    "video_capture.release()\n",
    "out.release()\n",
    "\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
